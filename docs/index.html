
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<meta charset="utf-8">
	<title>NSF Workshop in SE4Robotics</title>
	<meta name="author" content="drg" >
	<!--[if lt IE 9]>
		<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->
	<link href="./css/bootstrap.css" rel="stylesheet">
	<link href="./css/contenido.css" rel="stylesheet">
	<link rel="shortcut icon" href="favicon.ico">
<style type="text/css"></style></head>
<body>

<div class="topbar">
	<div class="topbar-inner">
		<div class="container1">
			<a class="brand" href="http://se4robotics.github.io/"><abbr
				title="NSF Sponsored Workshop in Software Engineering for Robotics">SE4Robotics'23</abbr></a>
			<ul class="nav">
				<li><a href="https://conf.researchr.org/home/icse-2023" target="_blank">Co-located with
				<abbr title="Internation Conference on Intelligent Robots and Systems">IROS</abbr> 2023</a>
				</li>
			</ul>
			<ul class="secondary-nav">
			<h5><a href="./cfp_pc.pdf">
			October 5-6, 2023, Detroit, MI
			</a></h5>
			</ul>
		</div>
	</div>
</div>

<div class="container">
	<div class="content">
		 
		<div class="row">
			<div class="span16">
				<p>&nbsp;</p><p>&nbsp;</p>
				<img src="./images/detroit.jpeg" style=' width: 100%;'/>
			</div>
		</div>
	
		<div class="hero-unit portada">
		   	<div style="float: right; width: 235px; margin: -25px;">
				<div class="calendar">
					<span class="month">Ocotber 2023</span>
					<span class="day">5-6</span>
				</div>
			</div>
			
			<h1><abbr title="Workshop on Software Engineering for Robotics">SE4Robotics'23</abbr><br></h1>
			<p>
				The NSF sponsored Workshop brings together academic researchers, industry researchers, and practitioners interested in addressning key software engineering challenges in robotics.
				
				<br/>
				<br/>
				
				Co-located with IROS’23, the SE4Robotics’23 meeting will include
				keynotes on software development in robotics from different perspectives. SE4Robotics’23
				will also host panel sessions to invite researchers and
				the audience to engage in discussion.
				
				<br/>
				<br/>
				 
				
		</div>
		
		<hr>
		
		<div class="row">
			<div class="span4">
				<h2>What is software fairness?</h2>
				As a society, we decide what attributes influence certain behavior. For example, race should not affect access to financial loans.
				Examples of real-world software exhibiting bias include image search and translation engines exhibiting gender stereotypes and facial detection and recognition tools’ depending on demographics.
			</div>
			<div class="span1">
				&nbsp;
			</div>
			<div class="span4">
				<h2>Is there research on software fairness?</h2>
				There are many software engineering challenges to building fair software that has not been addressed, from specifying fairness requirements to analysis, testing, and maintenance.
				FairWare 2023 will bring together academic and industry researchers and industry practitioners interested in creating software engineering technology to improve software fairness.
			</div>
			<div class="span1">
				&nbsp;
			</div>
			<div class="span6">
				<h2>Why do we need more research on software fairness?</h2>
				Recently, the requirements for fairer AI have become more common. The European Union, Microsoft, and the IEEE have all released white papers discussing fair and ethical AI.
				While these  documents differ in the details,  they all agree that  ethical AI must be ``FAT'';
				i.e., fair, accountable and transparent. Such fairer "FAT"er AI systems support five ``FAT'' items:
				
				<ul>
					<li> Integration with <b>human agency</b>
					<li> <b>Accountability</b> where conclusions are challenged
					<li> <b>Transparency</b> of how conclusions are made
					<li> Oversight on what must change to <b>fix bad conclusions</b>
					<li> <b>Inclusiveness</b> such that no specific segment of society is especially and unnecessarily privileged or discriminated against by the actions of the AI.
				</ul>
			</div>
		</div>
		
		<hr>
		
		<div class="row">
			<div class="span8">
				<h2>Special Issue <abbr title="Call For Papers">CFP</abbr></h2>
				Following on from the workshop, there will be a journal special issue at the Journal of Systems and Software: “Over the horizon: Limits and breakthroughs in algorithmic fairness. What are our next steps?” (Dates TBD). As far as possible, reviewers from Fairware'23 will be reused for the journal special issue (so authors should know what revisions are required to turn their Fairware'23 paper into a journal paper).
				<br/> <br/>
				
<!--				<p style="padding: 0 0 0 0px;"><a href="https://github.com/emsejournal/emsejournal.github.io/blob/master/special_issues/2022_Equitable_Data_and_Technology.md" class="btn primary large" target="_blank">Special Issue CFP</a>-->
			</div>
			<div class="span2">
				&nbsp;
			</div>
			<div class="span6">
				<h2>FairWare Resources</h2>
				The FairWare conference is over, and what an experience it was! We gathered many resources, open questions and ideas for future FairWare editions from our great discussions. These are available in the link below. You are welcome to leave new ideas or resources as well!
				
				<br/> <br/>
				
				<p style="padding: 0 0 0 0px;"><a href="https://docs.google.com/document/d/1Pt5PDyL8nPDJDRDyC2jJx4Lyb7xMUltKVVESgJk5Gg0/edit#" class="btn primary large" target="_blank">Link to resources</a>
			</div>
		</div>

		<hr>

		<div class="row">
			<div class="span16">
			<img align=right src=".\images\Keyes.png" width=400>
				<h2>Keynote: Fairness through Unfairness </h2>
					<p> Producing fair outcomes in a structural sense may actually require deliberately weighting software in favour of marginalised populations. 
						The question of how to make algorithmic systems fair is a common one for researchers concerned with the social consequences of 
						automation and machine learning. But what if it is the wrong question? What if the right one is to ask how we might make things unfair?
						In this talk, I will posit precisely that. Drawing on illustrative examples from housing to hiring, along with the history of 
						fairness as a concept, I will argue that - taking into account the broader contexts of algorithmic systems - achieving fair 
						outcomes may require developers to work towards unfair outcomes, first. </p>
				<br/>
				<p>Speaker:  <b>Os Keyes </b> <a href=" https://ironholds.org/"> https://ironholds.org/</a><br>
					Os Keyes is a PhD Candidate at the University of Washington’s Department of Human Centred Design & Engineering. <b>Details TBD!</b>
			</div>
			 
		</div>

        <hr>
		<div class="row">
			<div class="span16">
			<img align=right src=".\images\austin_photo.jpg" width=400>
				<h2>Keynote: Seldonian Toolkit </h2>
					<p> Software systems that use machine learning are routinely deployed in a wide range of settings, including medical applications, the criminal
					justice system, hiring, facial recognition, social media, and advertising.
					These systems can produce unsafe and unfair behavior, such as suggesting
					harmful medical treatments, making racist or sexist recommendations, and
					facilitating radicalization and polarization in society.
					To address this, we developed the Seldonian
					Toolkit for training machine learning models that adhere to fairness and safety requirements. The models the toolkit
					produces are probabilistically verified: they are guaranteed, with high
					probability, to satisfy the specified safety or fairness requirements even
					when applied to previously unseen data. The toolkit is a set of open source Python packages which are available to download. A video demonstrating the
					Seldonian Toolkit is available at <a href="https://youtu.be/wHR-hDm9jX4/"> https://youtu.be/wHR-hDm9jX4/</a> . </p>
				<br/>
				<p>Speaker:  <b>Austin Hoag </b> <br>
					Dr. Austin Hoag is a machine learning engineer at the Berkeley Existential Risk Initiative (BERI),
					a nonprofit that collaborates with university research groups working to reduce existential risk.
					He is the co-creator and lead software engineer for the Seldonian Toolkit, a collaboration with
					machine learning researchers at the University of Massachusetts. Before BERI, he worked as a software
					developer at the Princeton Neuroscience Institute at Princeton University. He received his PhD in
					Physics from the University of California, Davis in 2018 and conducted postdoctoral research in astrophysics at UCLA.
			</div>

		</div>

        <hr>


		
			

		</div>


		<hr>

        <div class="row">
            <div class="span16">
                <h2>Tentative Schedule</h2>
                <h3>Day 1</h3>
				<br> 8:45 - 9:00 <strong>Welcome</strong> </br>
				<br> 9:00 - 10:00 <strong>Framing Talks</strong> </br>
				<br> 10:00 - 10:30 <strong>Coffee and networking</strong> </br>
				<br> 11:00 - 12:30 <strong>Small Group brainstorm and ideation</strong> </br>
				<br> 12:30 - 13:30 <strong>Lunch and networking</strong> </br>
				<br> 13:30 - 14:30 <strong>Framing Talks</strong> </br>
				<br> 14:30 - 15:00 <strong>Coffee and networking</strong> </br>
				<br> 15:00 - 17:00 <strong>Themes development</strong> </br>
				<br> 18:00 - 19:30 <strong>Light Reception</strong> </br>
                <h3>Day 2</h3>
                <br> 8:45 - 9:00 <strong>Recap of Day 1</strong> </br>
				<br> 10:00 - 10:30 <strong>Coffee and networking</strong> </br>
				<br> 11:00 - 12:30 <strong>Synthesis and priorities</strong> </br>
				<br> 12:30 - 13:30 <strong>Lunch and networking</strong> </br>
				<br> 13:30 - 15:00 <strong>Summary presentations and plans</strong> </br>
				<br> 15:00 - 15:30 <strong>Closing</strong> </br>
         </div>
            </div>
        <hr>



		<div class="row">
			<div class="span14">
				<h2>Topics of Interest</h2>
				<p>
				<li>Programming languages that account for uncertainty and variability</li>
				<li>Abstractions that accommodate the richer notions of system state in robotics</li>
				<li>Mechanisms that integrate heterogeneous software and hardware</li>
				<li>Reference architectures that support environmental adaptation</li>
				<li>Development techniques that reduce and account for the simulation-reality gap</li>
				<li>Certification and assurance cases for robot software and hardware software/integrations</li>
				<li>Design & analysis techniques that transcend programmed/learned barriers</li>
				<li>Processes that support simultaneous evolution of physical & cyber components</li>
				<li>Assured composition of machine-learned components with conventional components</li>
				<li>Distribution and deployment at high-scale and at high-speed</li>
				<li>Curricula for software engineering to roboticists, and robotics to software engineers</li>
				<li>Libraries/frameworks/reusable components in the presence of extreme diversity</li>
				<li>Maintenance and sustainability of robots with long and continuous deployments</li>
				 </p>
			</div>
		</div>

		<hr>


		
	
		<div class="row">
			<div class="span6">
				<h2>Organization</h2>

				<h3>Chairs</h3>
					<ul>
						<li>Claire Le Goues, Associate Professor of, Carnegie Mellon University.</li>
						<li>Sebastian Elbaum, Anita Jones Professor, niversity of Virginia.</li>
					</ul>
				<h3>Steering Committee</h3>
					<ul>
						<li> Bill Smart, Professor of Mechanical Engineering and Robotics, Oregon State University</li> 
						<li>Brian Gerkey, CEO and Co-Founder, Open Robotics. </li> 
						<li> David Wettergreen, Research Professor, the Robotics Institute at Carnegie Mellon University. </li> 
						<li> Xiangyu Zhang, Professor of Computer Science, Purdue University. </li> 
					</ul>
                <h3>NSF Liasons</h3>
                    <ul>
                        <li> Sol Greenspan</li>  
                        <li> TBC</li> 
                    </ul>                        
			</div>
		</div>
	</div>
	
	<hr>
		
	<footer>
		<div class="secondary-nav">
			<p><abbr title="Workshop on Software Engineering for Robotics">SE4Robotics</abbr>'23</a>
		</div>
	</p>
	</footer>
</div>

</body>
</html>
