
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<meta charset="utf-8">
	<title>Fairware'23</title>
	<meta name="author" content="drg" >
	<!--[if lt IE 9]>
		<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->
	<link href="./css/bootstrap.css" rel="stylesheet">
	<link href="./css/contenido.css" rel="stylesheet">
	<link rel="shortcut icon" href="favicon.ico">
<style type="text/css"></style></head>
<body>

<div class="topbar">
	<div class="topbar-inner">
		<div class="container1">
			<a class="brand" href="http://fairwares.github.io/"><abbr
				title="International Workshop on Equitable Data and Technology">Fairware'23</abbr></a>
			<ul class="nav">
				<li><a href="https://conf.researchr.org/home/icse-2023" target="_blank">In conjunction with
				<abbr title="International Conference on Software Engineering">ICSE</abbr> 2023</a>
				</li>
			</ul>
			<ul class="secondary-nav">
			<h5><a href="./cfp_pc.pdf">
			May 14, 2022, Melbourne, Australia
			</a></h5>
			</ul>
		</div>
	</div>
</div>
<!-- div style="background-image">
	<mg src="./images/fairware.jpg" style='height: 85%; width: 100%; object-fit: contain'/>
	 
</div -->

<div class="container">
	<div class="content">
		 
		<div class="row">
			<div class="span16">
				<p>&nbsp;</p><p>&nbsp;</p>
				<img src="./images/Skyline.jpg" style=' width: 100%;'/>
			</div>
		</div>
	
		<div class="hero-unit portada">
		   	<div style="float: right; width: 235px; margin: -25px;">
				<div class="calendar">
					<span class="month">May 2023</span>
					<span class="day">14</span>
				</div>
			</div>
			
			<h1><abbr title="International Workshop on Equitable Data and Technology">Fairware'23</abbr><br></h1>
			<p>
				The International Workshop on Equitable Data & Technology brings together academic researchers, industry researchers, and practitioners interested in exploring ways to build <b>fairer, more equitable</b>, data-driven software.
				
				<br/>
				<br/>
				
				Co-located with ICSE’23, the FairWare’23 meeting will include
				keynotes on software fairness form different perspectives. FairWare’23
				will also host panel sessions to invite researchers and
				the audience to engage in discussion.
				
				<br/>
				<br/>
				
				Since many issues associated with fairness are often sociological in
				nature, we welcome <b>commentaries from outside of computer
				science</b> that can shed light on the complex issue of fairness.
				
				<p style="padding: 0 0 0 0px;"><a href="./cfp_pc.pdf" class="btn primary large" target="_blank"><abbr title="Call For Papers">CFP</abbr> in PDF</a>
			</p>
		</div>
		
		<hr>
		
		<div class="row">
			<div class="span4">
				<h2>What is software fairness?</h2>
				As a society, we decide what attributes influence certain behavior. For example, race should not affect access to financial loans.
				Examples of real-world software exhibiting bias include image search and translation engines exhibiting gender stereotypes and facial detection and recognition tools’ depending on demographics.
			</div>
			<div class="span1">
				&nbsp;
			</div>
			<div class="span4">
				<h2>Is there research on software fairness?</h2>
				There are many software engineering challenges to building fair software that has not been addressed, from specifying fairness requirements to analysis, testing, and maintenance.
				FairWare 2023 will bring together academic and industry researchers and industry practitioners interested in creating software engineering technology to improve software fairness.
			</div>
			<div class="span1">
				&nbsp;
			</div>
			<div class="span6">
				<h2>Why do we need more research on software fairness?</h2>
				Recently, the requirements for fairer AI have become more common. The European Union, Microsoft, and the IEEE have all released white papers discussing fair and ethical AI.
				While these  documents differ in the details,  they all agree that  ethical AI must be ``FAT'';
				i.e., fair, accountable and transparent. Such fairer "FAT"er AI systems support five ``FAT'' items:
				
				<ul>
					<li> Integration with <b>human agency</b>
					<li> <b>Accountability</b> where conclusions are challenged
					<li> <b>Transparency</b> of how conclusions are made
					<li> Oversight on what must change to <b>fix bad conclusions</b>
					<li> <b>Inclusiveness</b> such that no specific segment of society is especially and unnecessarily privileged or discriminated against by the actions of the AI.
				</ul>
			</div>
		</div>
		
		<hr>
		
		<div class="row">
			<div class="span8">
				<h2>Special Issue <abbr title="Call For Papers">CFP</abbr></h2>
				Following on from the workshop, there will be a journal special issue at the Journal of Systems and Software: “Over the horizon: Limits and breakthroughs in algorithmic fairness. What are our next steps?” (Dates TBD). As far as possible, reviewers from Fairware'23 will be reused for the journal special issue (so authors should know what revisions are required to turn their Fairware'23 paper into a journal paper).
				<br/> <br/>
				
<!--				<p style="padding: 0 0 0 0px;"><a href="https://github.com/emsejournal/emsejournal.github.io/blob/master/special_issues/2022_Equitable_Data_and_Technology.md" class="btn primary large" target="_blank">Special Issue CFP</a>-->
			</div>
			<div class="span2">
				&nbsp;
			</div>
			<div class="span6">
				<h2>FairWare Resources</h2>
				The FairWare conference is over, and what an experience it was! We gathered many resources, open questions and ideas for future FairWare editions from our great discussions. These are available in the link below. You are welcome to leave new ideas or resources as well!
				
				<br/> <br/>
				
				<p style="padding: 0 0 0 0px;"><a href="https://docs.google.com/document/d/1Pt5PDyL8nPDJDRDyC2jJx4Lyb7xMUltKVVESgJk5Gg0/edit#" class="btn primary large" target="_blank">Link to resources</a>
			</div>
		</div>

		<hr>

		<div class="row">
			<div class="span16">
			<img align=right src=".\images\Keyes.png" width=400>
				<h2>Keynote: Fairness through Unfairness </h2>
					<p> Producing fair outcomes in a structural sense may actually require deliberately weighting software in favour of marginalised populations. <b>Details TBD!</b> </p>
				<br/>
				<p>Speaker:  <b>Os Keyes </b> <a href=" https://ironholds.org/"> https://ironholds.org/</a><br>
					Os Keyes is a PhD Candidate at the University of Washington’s Department of Human Centred Design & Engineering. <b>Details TBD!</b>
			</div>
			 
		</div>

        <hr>

		<div class="row">
			<div class="span9">
				<h2>Paper Submission</h2>
				<p>
				Papers will be submitted through <a href="https://fairware23.hotcrp.com/">HotCRP</a>, and will be subjected to <b>double-blind</b> reviews.
				Submissions must use the official “ACM Primary Article Template” from the <a href="http://www.acm.org/publications/proceedings-template">ACM proceedings template</a>.
				LaTeX users should use the sigconf option, as well as the review (to produce line numbers for easy reference by the reviewers) and anonymous (omitting author names) options.
				In addition, submitted papers must not exceed the 8-page limit, be written in English, must present an original contribution, and must not be published or under review elsewhere.
				</p>

				<p>
				Two members of the program committee will review
				each paper and the committee will select the papers for
				presentation at workshop based on quality, relevance, and
				the potential for starting meaningful and productive conversations.
				</p>

				<h2>Workshop Participation</h2>

				<p>
				At least one author of each accepted paper must register for the
				workshop. Each paper will be presented in a 15-20 minute presentation with follow-up questions and discussion.
				</p>

<!--				<h2>Special Issue</h2>-->
<!--				<p>-->
<!--					<b> TBD </b>-->
<!--				Following on from the workshop, there will be an open call for a special journal issue on fair and equitable data and technology.-->
<!--				In that special issue, reviewers from this workshop will review extended versions of the FairWare'22 papers. For more-->
<!--					details see our <a -->
<!--		              href="https://emsejournal.github.io/special_issues/2022_Equitable_Data_and_Technology.html">journal special issue call for papers</a>.-->
				</p>

			</div>

			<div class="span1">
				<p>&nbsp;</p>
			</div>

			<div class="span6">


				<h2>Important Dates</h2> <ul>
					<li>Submission:
					<strong> 13 Jan </strong></li>
					<li>Notification of acceptance:
					<strong>24 Feb</strong></li>
					<li>Camera-ready submission:
					<strong>17 Mar</strong></li>
					<li>Workshop date: <strong>2X
					May</strong></li>
<!--					<li>Submission for follow-up journal special issue: -->
<!--					<strong>Sept 15, 2022 [<a -->
<!--		              href="https://emsejournal.github.io/special_issues/2022_Equitable_Data_and_Technology.html">details</a>]</strong>-->
				</ul>
			</div>
		</div>


		<hr>

        <div class="row">
            <div class="span16">
                <h2>Schedule</h2>
			    <br>TBD </br>
        </div>
            </div>
        <hr>



		<div class="row">
			<div class="span14">
				<h2>Topics of Interest</h2>
<!--				<ul>-->
<!--					<li><b>Socio-technical challenges</b></li>-->
<!--					<ul>-->
<!--						<li>How to determine the <b>trade-off</b> between making fair(er) systems and other objectives of a system?</li>-->
<!--						<li>How do we build equitable software given the inherently unfair social pressures behind it?</li>-->
<!--					</ul>-->
<!--					<li><b>Algorithmic challenges</b></li>-->
<!--					<ul>-->
<!--						<li>How to <b>identify bias</b> in AI models?</li>-->
<!--						<li>How to <b>explain</b> the source or reason for this bias?</li>-->
<!--						<li>How to <b>measure</b> the level of bias in systems?</li>-->
<!--						<li>How to <b>mitigate</b> the effect of this bias by changing how models are trained?</li>-->
<!--						<li>How to <b>provide</b> support for explanation of automated decisions and redress for stakeholders and other mechanisms for accountability and transparency of deployed systems?</li>-->
<!--					</ul>-->
<!--				</ul>-->
				<p>
					To support fairer “FAT”er software we aims to empower software developers, individuals and organizations,
					with methods and tools that <b>measure</b>, <b>manage</b>, and <b>mitigate</b> unfairness.
					Therefore we ask for papers that explore:
					<ul>
				<li>How to <b>identify</b> bias in AI models?</li>
				<li>How to <b>explain</b> the source or reason for this bias?</li>
				<li>How to <b>measure</b> the level of bias on these systems?</li>
				<li>How to <b>mitigate</b> bias by changing model training?</li>
				<li> How to <b>support</b> for explanations of automated decisions
						and redress for stakeholders for accountability and transparency of deployed systems? </li>
				<li> How to <b>determine</b> the trade-off between making fair(er) systems and other objectives of a system?</li>
				<li> Are there <b>inherently unfair social pressures</b> that doom us to forever delivering unfair software?</li>
					</ul>
				</p>
				<p>
					We are accepting contributions as full papers (4--8 pages),
					with either novel research results or a statement of vision or position, on one or more of the following perspectives:
					<ul>
						<li> <b>Improving fairness</b> -- Present a novel approach or evaluate
						an existing approach for software fairness. This can be along
						the lines, but not limited to identification, explanation, measurement, and mitigation of fairness.</li>
						<li><b>Applying fairness</b> -- artificial intelligence, machine learning,
						requirements and design, testing, software engineering cycle,
						and policy-making, among many other areas of interest.</li>
						<li><b>Pose challenges</b> -- Show the weak points in fairness methods, and lead the way on the path to novel research.
						Request new models, processes, metrics, and artifacts.</li>
						<li><b>Collaboration studies</b> -- Between researchers & industry,
						across the industry, across domains and disciplines, or col-
						laborations between research groups.</li>
					</ul>
				</p>

			</div>
		</div>

		<hr>


		
	
		<div class="row">
			<div class="span10">

				<h2>Programme Committee</h2>

				<li>Joymallya Chakraborty, Amazon</li>
				<li>Alex Groce, Northern Arizona University</li>
				<li>Christine Julien, University of Texas at Austin</li>
				<li>Os Keyes, University of Washington</li>
				<li>Rahul Pandita, GitHub</li>
				<li>Siobahn Day Grady, North Carolina Central University</li>
				<li>Gema Rodriguez-Perez, University British Columbia</li>
				<li>Muhammad Ali Gulzar, Virginia Tech</li>
				<li>Mei Nagappan, University of Waterloo</li>
				<li>Kevin Moran, George Mason University</li>
				<li>Lelia Marie Hampton, Massachusetts Institute of Technology</li>
				<li>Robert DeLine, Microsoft Research</li>
				<li>Marc Canellas, Office of the Public Defender for Arlington County and the City of Falls Church</li>
				<li>Mats Heimdahl, University of Minnesota</li>


						
					</ul>
				</div>
			<div class="span6">
				<h2>Organizing Committee</h2>
				<ul>
					<li>Brittany Johnson, George Mason University, USA</li>
					<li>Tim Menzies, NC State University, USA</li>
					<li>Federica Sarro, University College, UK.</li>
					<li>Zhe Yu, Rochester Institute of Technology, USA</li>
					<li>Yuriy Brun, U.Massachusetts, USA</li>
					<li>Jeanna Matthews, Clarkson University, USA</li>
					<li>Alicia Boyd, DePaul University, USA</li>
					<li>Justin Smith, Lafayette College, USA</li>

				</ul>
			</div>
		</div>
	</div>
	
	<hr>
	
	<div class="row">
		<div class="span10">
			<h2>Previous editions</h2>
			<ul>
			<li>2018 - <a href="https://fairware.cs.umass.edu/" target="_blank">https://fairware.cs.umass.edu/</a> - <a href="https://dl.acm.org/doi/proceedings/10.1145/3194770" target="_blank">ACM DL</a>
			<li>2022 - <a href="https://github.com/fairwares/fairwares.github.io/blob/main/docs/images/Fairware'22.pdf" target="_blank">https://github.com/fairwares/fairwares.github.io/blob/main/docs/images/Fairware'22.pdf/</a>
			</ul>
		</div>
	</div>
	
	<footer>
		<div class="secondary-nav">
			<p><abbr title="International Workshop on Equitable Data and Technology">FairWare</abbr>'23</a>
		</div>
	</p>
	</footer>
</div>

</body>
</html>
